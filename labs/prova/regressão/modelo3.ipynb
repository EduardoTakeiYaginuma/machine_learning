{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 1. Carregar e preparar os dados\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\"\n",
    "column_names = [\"mpg\", \"cylinders\", \"displacement\", \"horsepower\", \"weight\", \n",
    "                \"acceleration\", \"model year\", \"origin\", \"car name\"]\n",
    "df = pd.read_csv(url, names=column_names, na_values=\"?\", comment=\"\\t\", sep=\" \", skipinitialspace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------- PRE PROCESSAMENTO ---------------------------#\n",
    "df = df.drop('car name', axis=1)\n",
    "df['origin'] = df['origin'].astype('category')\n",
    "df['horsepower'] = pd.to_numeric(df['horsepower'], errors='coerce')\n",
    "df = df.dropna()\n",
    "\n",
    "print(\"Primeiras linhas do DataFrame após limpeza:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#--------------------------- ANÁLISE EXPLORATÓRIA ---------------------------#\n",
    "print(\"\\nEstatísticas descritivas:\")\n",
    "print(df.describe().T)\n",
    "\n",
    "# Matriz de correlação\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Matriz de Correlação')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Pairplot para visualizar relações entre variáveis\n",
    "sns.pairplot(df, vars=['mpg', 'weight', 'horsepower', 'acceleration'])\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(bins=30, figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weight'] = df['weight'].apply(np.log10)\n",
    "df['horsepower'] = df['horsepower'].apply(np.log10)\n",
    "df[\"displacement\"] = df[\"displacement\"].apply(np.log10)\n",
    "df.hist(bins=30, figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------Remoção de Outliers--------------------------------\n",
    "# Utilizando Z-Score\n",
    "# Z= (X−μ)/σ\n",
    "# onde:\n",
    "# X é o valor do ponto de dados,\n",
    "# μ é a média do conjunto de dados,\n",
    "# σ é o desvio padrão do conjunto de dados.\n",
    "\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_columns.remove('mpg')  # Remover a variável alvo\n",
    "\n",
    "def remove_outliers(df, columns, z_threshold):\n",
    "    for col in columns:\n",
    "        z_scores = np.abs((df[col] - df[col].mean()) / df[col].std())\n",
    "        df = df[z_scores < z_threshold]\n",
    "    return df\n",
    "\n",
    "print (\"\\nTamanho do DataFrame antes da remoção de outliers:\")\n",
    "print(df.shape)\n",
    "\n",
    "# Quanto MAIOR o valor de z_threshold, MENOS outliers serão removidos\n",
    "z_threshold = 3\n",
    "df = remove_outliers(df, numeric_columns, z_threshold)\n",
    "\n",
    "print(\"\\nTamanho do DataFrame após remoção de outliers:\")\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------- FEATURE ENGENEERING ---------------------------#\n",
    "print(\"Primeiras linhas do DataFrame antes de feature engineering:\")\n",
    "print(df.head())\n",
    "# Normalização\n",
    "scaler = StandardScaler()\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_columns.remove('mpg')\n",
    "df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "# One-hot encoding para 'origin'\n",
    "df = pd.get_dummies(df, columns=['origin'], prefix='origin')\n",
    "\n",
    "# Criação de features polinomiais\n",
    "X = df.drop('mpg', axis=1)\n",
    "y = df['mpg']\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(X)\n",
    "feature_names = poly.get_feature_names_out(X.columns)\n",
    "X_poly = pd.DataFrame(X_poly, columns=feature_names)\n",
    "print(\"\\nPrimeiras linhas do DataFrame após feature engineering:\")\n",
    "print(X_poly.head())\n",
    "\n",
    "#As features polinomiais ajudam a melhorar a capacidade do modelo de regressão de representar relações\n",
    "#complexas nos dados, permitindo que ele capture comportamentos não lineares que uma abordagem linear \n",
    "#simples não conseguiria. Isso pode resultar em previsões mais precisas quando há uma relação não linear entre \n",
    "#as variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#------------------------------- MODELAGEM -------------------------------#\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\"\"\n",
    "Podem haver casos que X não possui inversa e portanto não é possivel calcular o theta. \n",
    "Por isso, o ridge adiciona um termo alpha*I onde I é a matriz identidade à matrix XtX\n",
    "para garantir que ela seja inversível. \n",
    "O ideia é testar sem regularização e se não for possivel calcular o theta, usar a regularização.\"\"\")\n",
    "\n",
    "# -------------------------------- MODELO USANDO NORMAL --------------------------------\n",
    "\n",
    "\n",
    "\n",
    "def normal_equation_pseudoinverse(X, y):\n",
    "    return np.linalg.pinv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "\n",
    "# Adiciona a coluna de bias\n",
    "X_train_with_bias = np.column_stack([np.ones(X_train.shape[0]), X_train])\n",
    "\n",
    "# def normal_equation(X, y):\n",
    "#     return np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "\n",
    "# X_train_with_bias = np.column_stack([np.ones(X_train.shape[0]), X_train])\n",
    "# theta_normal = normal_equation(X_train_with_bias, y_train)\n",
    "\n",
    "# Calcula theta usando a pseudoinversa \n",
    "# Aqui temos uma matriz com os valores de theta para cada feature\n",
    "theta_normal = normal_equation_pseudoinverse(X_train_with_bias, y_train)\n",
    "\n",
    "# Equação Normal\n",
    "X_test_ = np.column_stack([np.ones(X_test.shape[0]), X_test])\n",
    "y_pred_normal = X_test_.dot(theta_normal)\n",
    "mse_normal = mean_squared_error(y_test, y_pred_normal)\n",
    "r2_normal = r2_score(y_test, y_pred_normal) \n",
    "\n",
    "# ------------------------------- MODELO USANDO SKLEARN -------------------------------\n",
    "\n",
    "model_sklearn = LinearRegression()\n",
    "model_sklearn.fit(X_train, y_train)\n",
    "\n",
    "# theta_normal = np.concatenate([[model_sklearn.intercept_], model_sklearn.coef_])\n",
    "\n",
    "y_pred_sklearn = model_sklearn.predict(X_test)\n",
    "mse_sklearn = mean_squared_error(y_test, y_pred_sklearn)\n",
    "r2_sklearn = r2_score(y_test, y_pred_sklearn)\n",
    "\n",
    "# ------------------------------- MODELO USANDO RIDGE (L2) -------------------------------\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Define o valor de alpha para a regularização Ridge\n",
    "alpha = 1e-3  # Este valor pode ser ajustado conforme necessário\n",
    "\n",
    "# Criar o modelo de Ridge Regression\n",
    "ridge_model = Ridge(alpha=alpha)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "theta_normal = np.concatenate([[ridge_model.intercept_], ridge_model.coef_])\n",
    "\n",
    "# Predição e avaliação com o modelo Ridge\n",
    "y_pred_ridge = ridge_model.predict(X_test)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "# ------------------------------- COMPARAÇÃO DE MODELOS -------------------------------\n",
    "\n",
    "print(\"\\nComparação de modelos:\")\n",
    "\n",
    "# Resultados da Equação Normal\n",
    "print(f\"Equação Normal: \")\n",
    "print(f\"MSE: {mse_normal:.4f}, R²: {r2_normal:.4f}\")\n",
    "# Printa a equação com os valores de theta\n",
    "print(f\"cyl*{theta_normal[1]:.4f} disp*{theta_normal[2]:.4f} hp*{theta_normal[3]:.4f} weight*{theta_normal[4]:.4f} ...\")\n",
    "\n",
    "# Resultados do Sklearn\n",
    "print(f\"\\nSklearn: \")\n",
    "print(f\"MSE: {mse_sklearn:.4f}, R²: {r2_sklearn:.4f}\")\n",
    "print(f\"cy*{model_sklearn.coef_[0]:.4f} disp*{model_sklearn.coef_[1]:.4f} hp*{model_sklearn.coef_[2]:.4f} weight*{model_sklearn.coef_[3]:.4f} ...\")\n",
    "\n",
    "# Resultados da Ridge Regression\n",
    "print(f\"\\nRidge Regression: \")\n",
    "print(f\"MSE: {mse_ridge:.4f}, R²: {r2_ridge:.4f}\")\n",
    "print(f\"cy*{ridge_model.coef_[0]:.4f} disp*{ridge_model.coef_[1]:.4f} hp*{ridge_model.coef_[2]:.4f} weight*{ridge_model.coef_[3]:.4f} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "feature_names = ['Intercept'] + list(X_train.columns)\n",
    "\n",
    "# Criar DataFrame para os coeficientes\n",
    "coef_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': theta_normal})\n",
    "coef_df = coef_df.sort_values('Coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\nCoeficientes mais significativos:\")\n",
    "print(coef_df.head(10))\n",
    "\n",
    "print(\"\\nInterpretação dos coeficientes mais significativos:\")\n",
    "for _, row in coef_df.head(5).iterrows():\n",
    "    print(f\"{row['Feature']}: {row['Coefficient']:.4f}\")\n",
    "    print(f\"  Uma mudança de uma unidade em {row['Feature']} está associada\")\n",
    "    print(f\"  a uma mudança de {row['Coefficient']:.4f} em mpg, mantendo\")\n",
    "    print(f\"  todas as outras variáveis constantes.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "# Actual vs. Predicted Values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_normal, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('MPG Real')\n",
    "plt.ylabel('MPG Previsto')\n",
    "plt.title('Valores Reais vs. Previstos (Equação Normal)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Residuals\n",
    "residuals = y_test - y_pred_normal\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred_normal, residuals)\n",
    "plt.xlabel('Valores Previstos')\n",
    "plt.ylabel('Resíduos')\n",
    "plt.title('Gráfico de Resíduos (Equação Normal)')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature Importance\n",
    "plt.figure(figsize=(12, 6))\n",
    "coef_df.head(10).plot(x='Feature', y='Coefficient', kind='bar')\n",
    "plt.title('Top 10 Coeficientes do Modelo (Equação Normal)')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Coeficiente')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
